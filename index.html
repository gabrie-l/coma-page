<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="description"
      content="CoMA: Compositional Human Motion Generation with Multi-modal Agents"
    />
    <meta
      name="keywords"
      content="Human Motion Generation, Multi-modal Generation, Self-correcting framework"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      Home - CoMA: Compositional Human Motion Generation with Multi-modal Agents
    </title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }

      gtag("js", new Date());

      gtag("config", "G-PYVRSFMDRL");
    </script>
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="/coma-page/static/css/bulma.min.css" />
    <link
      rel="stylesheet"
      href="/coma-page/static/css/bulma-carousel.min.css"
    />
    <link rel="stylesheet" href="/coma-page/static/css/bulma-slider.min.css" />
    <link
      rel="stylesheet"
      href="/coma-page/static/css/fontawesome.all.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="/coma-page/static/css/index.css" />
    <link rel="icon" href="/coma-page/static/images/favicon.svg" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="/coma-page/static/js/fontawesome.all.min.js"></script>
    <script src="/coma-page/static/js/bulma-carousel.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bulma-carousel/3.0.0/js/bulma-carousel.min.js"></script>

    <script src="/coma-page/static/js/bulma-slider.min.js"></script>
    <script src="/coma-page/static/js/index.js"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function () {
        console.log("DOM fully loaded and parsed");

        let carousels = bulmaCarousel.attach("#results-carousel", {
          slidesToScroll: 1,
          slidesToShow: 1,
          loop: true,
          autoplay: true,
          autoplaySpeed: 6000,
          pauseOnHover: true,
          infinite: true,
        });

        console.log("Carousel initialized:", carousels);
      });
    </script>
    <style>
      /* Increase the font size of the captions and make them bold */
      .carousel-item h3 {
        font-size: 1.5em; /* Adjust the size as needed */
        font-weight: bold; /* Make the text bold */
        margin-bottom: 0.5em; /* Ensure there is some spacing below the captions */
      }

      /* Adjust the container to provide space for the indicators */
      .carousel-item {
        margin-bottom: 2em; /* Adjust margin to ensure indicator visibility */
      }

      /* Position carousel indicators directly below the video content */
      .carousel-indicators {
        text-align: center; /* Center-align the indicators */
        margin-top: 1em; /* Add top margin to space out indicators from the videos */
      }

      /* Ensure the container is positioned correctly below the carousel */
      #results-carousel .carousel-indicators {
        position: static;
      }

      /* Positioning the navigation buttons for left and right */
      .carousel-nav-left,
      .carousel-nav-right {
        position: absolute;
        top: 50%;
        transform: translateY(-50%);
        display: flex;
        align-items: center;
        justify-content: center;
        width: 50px;
        height: 50px;
        background-color: rgba(0, 0, 0, 0.5);
        color: white;
        border: none;
        cursor: pointer;
        z-index: 10;
      }

      .carousel-nav-left {
        left: 10px; /* Adjust the distance from the left edge */
      }

      .carousel-nav-right {
        right: 10px; /* Adjust the distance from the right edge */
      }
      .vertical-image {
        width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                CoMA: Compositional Human Motion Generation with Multi-modal
                Agents
              </h1>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <!-- Caption -->
            <div class="carousel-item item-steve">
              <h3 class="has-text-centered">This is a very cool motion!</h3>
              <video
                poster=""
                id="steve"
                autoplay
                controls
                muted
                loop
                playsinline
                height="100%"
              >
                <source
                  src="/coma-page/static/videos/placeholder1.mp4"
                  type="video/mp4"
                />
              </video>
            </div>
            <div class="carousel-item item-coffee">
              <h3 class="has-text-centered">
                This is another interesting motion
              </h3>
              <!-- Caption -->
              <video
                poster=""
                id="coffee"
                autoplay
                controls
                muted
                loop
                playsinline
                height="100%"
              >
                <source
                  src="/coma-page/static/videos/placeholder3.mp4"
                  type="video/mp4"
                />
              </video>
            </div>
            <div class="carousel-item item-toby">
              <h3 class="has-text-centered">Yet another motion</h3>
              <!-- Caption -->
              <video
                poster=""
                id="toby"
                autoplay
                controls
                muted
                loop
                playsinline
                height="100%"
              >
                <source
                  src="/coma-page/static/videos/placeholder2.mp4"
                  type="video/mp4"
                />
              </video>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                3D human motion generation has seen substantial advancement in
                recent years. While state of the art approaches have improved
                performance significantly, they still struggle with complex and
                detailed motions unseen in training data, largely due to the
                scarcity of motion datasets and the prohibitive cost of
                generating new training examples. To address these challenges,
                we introduce CoMA, an agent based solution for complex human
                motion generation, editing, and comprehension. CoMA leverages
                multiple collaborative agents powered by large language and
                vision models, alongside a mask transformer based motion
                generator featuring body part specific encoders and codebooks
                for fine grained control. Our framework enables generation of
                both short and long motion sequences with detailed instructions,
                text guided motion editing, and self correction for improved
                quality. Evaluations on the HumanML3D dataset demonstrate
                competitive performance against state of the art methods.
                Additionally, we create a set of context rich, compositional,
                and long text prompts, where user studies show our method
                significantly outperforms existing approaches.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Multi-modal agents</h2>
            <div class="content has-text-justified">
              <p>
                CoMA is designed around multi-modal agents. Taking advantage of
                modern Large Language Models (LLMs) and Video Language Models
                (VLMs), our framework's pipeline aggregates these
                functionalities within four independent agents: the Task
                Planner, Trajectory Editor, Motion Generator and Motion
                Reviewer. Below are brief descriptions of each agent, as well as
                an example workflow of CoMA.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <div class="container">
      <div class="columns is-centered">
        <!-- Column for paragraph content -->
        <div class="column is-one-third">
          <div class="content">
            <h2 class="title is-3">Task Planner</h2>
            <p>
              This agent leverages a LLM (GPT-4o) to perform its three
              designated tasks: Recaptioning, Temporal Composition and Task
              Decomposition. The user's input is reasoned to identify key
              elements of the described motion, removing any coloquial
              abstractions and possible ambiguities, as well as substituting any
              words unseen in the training data to ensure optimal functionality.
              Afterwards, the Task Planner decomposes the processed prompt into
              temporally consecutive segments, and for each one, it assigns a
              global motion and local editing tasks. Finally, these tasks are
              fit into four prompts, one for each body part.
            </p>
            <h2 class="title is-3">Trajectory Editor</h2>
            <p>
              If trajectory information is identified by the Task Planner, the
              Trajectory Editor prompts GPT-4o to generate a mathematical
              function to compute trajectory coordinates for the pelvis joint.
              This guides the entire generation sequence to follow the
              explicited path by the user.
            </p>
            <h2 class="title is-3">Motion Generator</h2>
            <p>
              After the text processing agents finalized their tasks, the Motion
              Generator agent, through SPAM, generates a motion sequence with
              the fine-grained, per-body-part instructions. Using four
              encoder-decoder pairs, one for each body-part instruction, this
              agent blends the generated tokens for each pair into a single
              embedding to create the final motion sequence.
            </p>
            <h2 class="title is-3">Motion Reviewer</h2>
            <p>
              Powered by an instruction fine-tuned VLM module (VideoChat2) using
              the colored human models rendered through Blender, the Motion
              Reviewer captions the sequence generated by SPAM and applies
              cosine similarity to gauge its relevancy to the original user
              prompt. If not above the arbitrary threshold, this agent initiates
              the self-correction pipeline, forwarding the current text
              instructions to the Task Planner for additional processing.
            </p>
          </div>
        </div>

        <!-- Column for image -->
        <div class="column is-two-thirds">
          <figure class="image is-3by4">
            <img
              class="vertical-image"
              src="static/figures/workflow.png"
              alt="Side image"
            />
          </figure>
        </div>
      </div>
    </div>

    <!-- <section class="section hero"> -->
    <!--    <div class="container is-max-desktop"> -->
    <!--     <div class="columns is-centered"> -->
    <!--       <div class="column is-6"> -->
    <!--         <div class="content"> -->
    <!--           <h2 class="title is-3">Task Planner</h2> -->
    <!--           <p> -->
    <!--             This agent leverages a LLM (GPT-4o) to perform its  -->
    <!--             three designated tasks: Recaptioning, Temporal Composition and Task Decomposition. -->
    <!--             The user's input is reasoned to identify key elements of the described motion, -->
    <!--             removing any coloquial abstractions and possible ambiguities, as well as substituting any  -->
    <!--             words unseen in the training data to ensure optimal functionality. Afterwards, the Task Planner decomposes -->
    <!--             the processed prompt into temporally consecutive segments, and for each one, it assigns a global motion and local editing tasks. -->
    <!--             Finally, these tasks are fit into four prompts, one for each body part. -->
    <!--           </p> -->
    <!--         </div> -->
    <!--       </div> -->
    <!---->
    <!--       <div class="column is-6"> -->
    <!--         <h2 class="title is-3">Trajectory Editor</h2> -->
    <!--         <div class="columns is-centered"> -->
    <!--           <div class="column content"> -->
    <!--             <p> -->
    <!--               If trajectory information is identified by the Task Planner, the Trajectory Editor prompts GPT-4o to -->
    <!--               generate a mathematical function to compute trajectory coordinates for the pelvis joint. This  -->
    <!--               guides the entire generation sequence to follow the explicited path by the user. -->
    <!--             </p> -->
    <!--           </div> -->
    <!--         </div> -->
    <!--       </div> -->
    <!--     </div> -->
    <!---->
    <!--     <div class="columns is-centered"> -->
    <!--       <div class="column is-6"> -->
    <!--         <div class="content"> -->
    <!--           <h2 class="title is-3">Motion Generator</h2> -->
    <!--           <p> -->
    <!--             After the text processing agents finalized their tasks, the Motion Generator agent, through SPAM, -->
    <!--             generates a motion sequence using the fine-grained, per-body-part instructions. Using four encoder-decoder pairs, -->
    <!--             one for each instruction type, this agent combines the tokens for each pair to create the final motion sequence. -->
    <!---->
    <!--           </p> -->
    <!--         </div> -->
    <!--       </div> -->
    <!---->
    <!--       <div class="column is-6"> -->
    <!--         <h2 class="title is-3">Motion Reviewer</h2> -->
    <!--         <div class="columns is-centered"> -->
    <!--           <div class="column content"> -->
    <!--             <p> -->
    <!--               Powered by an instruction fine-tuned VLM module (VideoChat2) using the colored human models rendered through Blender, -->
    <!--               the Motion Reviewer captions the sequence generated by SPAM and applies cosine similarity to gauge its relevancy to the original user -->
    <!--               prompt. If not above the arbitrary threshold, this agent initiates the self-correction pipeline, forwarding the current text instructions to the  -->
    <!--               Task Planner for additional processing. -->
    <!--             </p> -->
    <!--           </div> -->
    <!--         </div> -->
    <!--       </div> -->
    <!--     </div> -->
    <!-- </section> -->

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Longer motions</h2>
            <div class="content has-text-justified">
              <p>
                Placeholder text for longer motion generation
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Spatial composition</h2>
            <div class="content has-text-justified">
              <p>
                Placeholder text for Spaial composition motions
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Reasoning</h2>
            <div class="content has-text-justified">
              <p>
                Placeholder text for self-corretion loop
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Self correction</h2>
            <div class="content has-text-justified">
              <p>
                Placeholder text for self-corretion loop
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container has-text-centered">
          <h2 class="title is-3">CoMA overview</h2>
          <div class="column is-centered">
            <img src="static/figures/comp_framework.png" alt="cars peace" />
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-small">
      <div class="hero-body">
        <div class="container has-text-centered">
          <h2 class="title is-3">SPAM overview</h2>
          <div class="column is-centered">
            <img src="static/figures/SPAM.png" alt="cars peace" />
          </div>
        </div>
      </div>
    </section>
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
              <p>
                This means you are free to borrow the
                <a href="https://github.com/nerfies/nerfies.github.io"
                  >source code</a
                >
                of this website, we just ask that you link back to this page in
                the footer. Please remember to remove the analytics code
                included in the header of the website which you do not want on
                your website.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
